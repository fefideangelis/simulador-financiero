import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

export const config = {
  api: {
    bodyParser: false
  }
};

export default async function handler(req, res) {
  try {
    // üîß Leer el body manualmente
    const buffers = [];
    for await (const chunk of req) {
      buffers.push(chunk);
    }
    const data = JSON.parse(Buffer.concat(buffers).toString());
    const prompt = data.prompt;

    if (!prompt) {
      console.error("‚ùå Prompt no recibido");
      return res.status(400).json({ error: "Falta el prompt" });
    }

    console.log("üîç Prompt recibido:", prompt);

    const completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [{ role: "user", content: prompt }],
      temperature: 0.7
    });

    const respuesta = completion.choices?.[0]?.message?.content;

    if (!respuesta) {
      console.error("‚ùå La IA no devolvi√≥ respuesta");
      return res.status(500).json({ error: "La IA no respondi√≥" });
    }

    console.log("‚úÖ Respuesta generada:", respuesta);

    res.status(200).json({ resultado: respuesta });

  } catch (error) {
    console.error("üö® Error en funci√≥n IA:", error);
    res.status(500).json({ error: error.message || "Fallo la generaci√≥n con OpenAI" });
  }
}
